W0514 04:11:25.178000 21152 torch/distributed/run.py:793] 
W0514 04:11:25.178000 21152 torch/distributed/run.py:793] *****************************************
W0514 04:11:25.178000 21152 torch/distributed/run.py:793] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W0514 04:11:25.178000 21152 torch/distributed/run.py:793] *****************************************
fashion_mnist: 1000 labeled, 59000 unlabeled.
Avg candidates/labeled: 3.80, dist={3: 250, 4: 256, 2: 198, 5: 189, 7: 21, 6: 77, 8: 8, 9: 1}
fashion_mnist: 1000 labeled, 59000 unlabeled.
Avg candidates/labeled: 3.80, dist={3: 250, 4: 256, 2: 198, 5: 189, 7: 21, 6: 77, 8: 8, 9: 1}
/workspace/SPMI-Reproducibility-Study/fminstexp.py:162: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.
  scaler = torch.cuda.amp.GradScaler()
/workspace/SPMI-Reproducibility-Study/fminstexp.py:162: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.
  scaler = torch.cuda.amp.GradScaler()
/workspace/SPMI-Reproducibility-Study/fminstexp.py:57: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast():
/workspace/SPMI-Reproducibility-Study/fminstexp.py:57: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast():
[Epoch 50/500] Loss: 1.8828 Acc: 9.28% Best: 10.12%
[Epoch 100/500] Loss: 1.9185 Acc: 9.82% Best: 10.12%
[Epoch 150/500] Loss: 1.8647 Acc: 10.12% Best: 10.12%
[Epoch 200/500] Loss: 1.8753 Acc: 10.12% Best: 10.12%
[Epoch 250/500] Loss: 1.8685 Acc: 9.96% Best: 10.12%
[Epoch 300/500] Loss: 1.9433 Acc: 9.82% Best: 10.12%
[Epoch 350/500] Loss: 1.9073 Acc: 10.12% Best: 10.12%
[Epoch 400/500] Loss: 1.9580 Acc: 10.12% Best: 10.12%
[Epoch 450/500] Loss: 1.9023 Acc: 10.12% Best: 10.12%
[Epoch 500/500] Loss: 1.9229 Acc: 10.12% Best: 10.12%
â–¶ Results saved to fmnist_l1000_p0.3_s42_ddp.csv
